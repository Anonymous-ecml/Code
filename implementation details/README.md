# Implementation Details
## MIMIC-III physiologic deterioration prediction
For patient graph structure learning, the dimension size of hidden states in GRUs is 17, the number of attention heads is 4, and the initial value of the learnable threshold $\xi$ is 0.15. For patient graph structure refining, the number of disjoint clusters $K$ is 11, and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are 0.35 and 0.25, respectively. For contrastive learning, the sampling ratio $r$ is 0.4, the walk length $l_{walk}$ is 2, and the dimension sizes of $d_{E}$ and $d_{S}$ are 23 and 19, respectively. The temperature parameter $\tau$ is 0.5. The dropout method is applied to the Softmax output layer, and the dropout rate is 0.2. For supervised learning setting, the scaling parameters $\alpha_{1}$, $\alpha_{2}$, and $\lambda_{2}$ are 1.65, 0.92 and 0.75, respectively. 

## MIMIC-III LOS prediction (3 days)
For patient graph structure learning, the dimension size of hidden states in GRUs is , the number of attention heads is , and the initial value of the learnable threshold $\xi$ is . For patient graph structure refining, the number of disjoint clusters $K$ is , and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are and , respectively. For contrastive learning, the sampling ratio $r$ is , the walk length $l_{walk}$ is , and the dimension sizes of $d_{E}$ and $d_{S}$ are and , respectively. The temperature parameter $\tau$ is . The dropout method is applied to the Softmax output layer, and the dropout rate is . For supervised learning setting, the scaling parameters $\alpha_{1}$, $\alpha_{2}$, and $\lambda_{2}$ are , and , respectively. 

## MIMIC-III LOS prediction (7 days)
For patient graph structure learning, the dimension size of hidden states in GRUs is , the number of attention heads is , and the initial value of the learnable threshold $\xi$ is . For patient graph structure refining, the number of disjoint clusters $K$ is , and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are and , respectively. For contrastive learning, the sampling ratio $r$ is , the walk length $l_{walk}$ is , and the dimension sizes of $d_{E}$ and $d_{S}$ are and , respectively. The temperature parameter $\tau$ is . The dropout method is applied to the Softmax output layer, and the dropout rate is . For supervised learning setting, the scaling parameters $\alpha_{1}$, $\alpha_{2}$, and $\lambda_{2}$ are , , and , respectively. 

## MIMIC-III Self-supervised Learning Setting
For patient graph structure learning, the dimension size of hidden states in GRUs is , the number of attention heads is , and the initial value of the learnable threshold $\xi$ is . For patient graph structure refining, the number of disjoint clusters $K$ is , and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are and , respectively. For contrastive learning, the sampling ratio $r$ is , the walk length $l_{walk}$ is , and the dimension sizes of $d_{E}$ and $d_{S}$ are and , respectively. The temperature parameter $\tau$ is . The dropout method is applied to the Softmax output layer, and the dropout rate is . The scaling parameters $\beta_{1}$, $\beta_{2}$, and $\lambda_{1}$ are , , and respectively.

\textbf{eICU physiologic deterioration prediction}
For patient graph structure learning, the dimension size of hidden states in GRUs is , the number of attention heads is , and the initial value of the learnable threshold $\xi$ is . For patient graph structure refining, the number of disjoint clusters $K$ is , and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are  and , respectively. For contrastive learning, the sampling ratio $r$ is , the walk length $l_{walk}$ is , and the dimension sizes of $d_{E}$ and $d_{S}$ are  and , respectively. The temperature parameter $\tau$ is . The dropout method is applied to the Softmax output layer, and the dropout rate is . For supervised learning setting, the scaling parameters $\alpha_{1}$, $\alpha_{2}$, and $\lambda_{2}$ are ,  and , respectively. 

\textbf{eICU LOS prediction (3 days)}
For patient graph structure learning, the dimension size of hidden states in GRUs is , the number of attention heads is , and the initial value of the learnable threshold $\xi$ is . For patient graph structure refining, the number of disjoint clusters $K$ is , and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are and , respectively. For contrastive learning, the sampling ratio $r$ is , the walk length $l_{walk}$ is , and the dimension sizes of $d_{E}$ and $d_{S}$ are and , respectively. The temperature parameter $\tau$ is . The dropout method is applied to the Softmax output layer, and the dropout rate is . For supervised learning setting, the scaling parameters $\alpha_{1}$, $\alpha_{2}$, and $\lambda_{2}$ are , and , respectively. 

\textbf{eICU LOS prediction (7 days)}
For patient graph structure learning, the dimension size of hidden states in GRUs is , the number of attention heads is , and the initial value of the learnable threshold $\xi$ is . For patient graph structure refining, the number of disjoint clusters $K$ is , and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are and , respectively. For contrastive learning, the sampling ratio $r$ is , the walk length $l_{walk}$ is , and the dimension sizes of $d_{E}$ and $d_{S}$ are and , respectively. The temperature parameter $\tau$ is . The dropout method is applied to the Softmax output layer, and the dropout rate is . For supervised learning setting, the scaling parameters $\alpha_{1}$, $\alpha_{2}$, and $\lambda_{2}$ are , , and , respectively. 

\textbf{eICU Self-supervised Learning Setting}
For patient graph structure learning, the dimension size of hidden states in GRUs is , the number of attention heads is , and the initial value of the learnable threshold $\xi$ is . For patient graph structure refining, the number of disjoint clusters $K$ is , and the add and delete ratios $\gamma_{add}$ and $\gamma_{del}$ are and , respectively. For contrastive learning, the sampling ratio $r$ is , the walk length $l_{walk}$ is , and the dimension sizes of $d_{E}$ and $d_{S}$ are and , respectively. The temperature parameter $\tau$ is . The dropout method is applied to the Softmax output layer, and the dropout rate is . The scaling parameters $\beta_{1}$, $\beta_{2}$, and $\lambda_{1}$ are , , and respectively.
